import google.generativeai as genai
from chromadb import Documents, EmbeddingFunction, Embeddings
import chromadb
import os
import flask, requests, jsonify
from flask import Flask, request
from flask_cors import CORS

class GeminiEmbeddingFunction(EmbeddingFunction):
    """
    Custom embedding function using the Gemini AI API for document retrieval.

    This class extends the EmbeddingFunction class and implements the __call__ method
    to generate embeddings for a given set of documents using the Gemini AI API.

    Parameters:
    - input (Documents): A collection of documents to be embedded.

    Returns:
    - Embeddings: Embeddings generated for the input documents.

    Raises:
    - ValueError: If the Gemini API Key is not provided as an environment variable (GEMINI_API_KEY).

    Example:
    >>> gemini_embedding_function = GeminiEmbeddingFunction()
    >>> input_documents = Documents(["Document 1", "Document 2", "Document 3"])
    >>> embeddings_result = gemini_embedding_function(input_documents)
    >>> print(embeddings_result)
    Embeddings for the input documents generated by the Gemini AI API.
    """
    def __call__(self, input: Documents) -> Embeddings:
        gemini_api_key = os.getenv("GEMINI_API_KEY")
        if not gemini_api_key:
            raise ValueError("Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable")
        genai.configure(api_key=gemini_api_key)
        model = "models/embedding-001"
        title = "Custom query"
        return genai.embed_content(model=model,
                                   content=input,
                                   task_type="retrieval_document",
                                   title=title)["embedding"]
        
        
def load_chroma_collection(path, name):
    """
    Loads an existing Chroma collection from the specified path with the given name.

    Parameters:
    - path (str): The path where the Chroma database is stored.
    - name (str): The name of the collection within the Chroma database.

    Returns:
    - chromadb.Collection: The loaded Chroma Collection.
    """
    chroma_client = chromadb.PersistentClient(path=path)
    db = chroma_client.get_collection(name=name, embedding_function=GeminiEmbeddingFunction())

    return db




def make_rag_prompt(query, relevant_passage, val=1):
  escaped = relevant_passage.replace("'", "").replace('"', "").replace("\n", " ")
  if val==1:
      prompt = ("""As a helpful assistant, your task is to provide advice to Indian females who have experienced any form of crime against them those mentioned in the question. Your goal is to offer guidance on the legal actions they can take in response to the crimes committed. Provide supportive and informative advice to assist them in understanding their legal rights and options
      QUESTION: '{query}'
      PASSAGE: '{relevant_passage}'

      ANSWER:
      """).format(query=query, relevant_passage=escaped)
  else:
      prompt = ("""Sangrakshak is a unique chatbot designed to empower Indian women by providing anonymous and approachable legal support. Our mission is to assist women facing issues like domestic violence, sexual harassment, and privacy violations, ensuring they have access to information on their legal rights, procedures, and support resources. For general or chit-chat queries, such as asking about Sangrakshak or engaging in friendly conversation, please respond in a way that affirms Sangrakshak's identity as a supportive and informative chatbot while staying friendly and engaging.
      QUESTION: '{query}'
      PASSAGE: '{relevant_passage}'

      ANSWER:
      """).format(query=query, relevant_passage=escaped)

  return prompt



def generate_answer_api(prompt):
    gemini_api_key = os.getenv("GEMINI_API_KEY")
    if not gemini_api_key:
        raise ValueError("Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable")
    genai.configure(api_key=gemini_api_key)
    model = genai.GenerativeModel('gemini-pro')
    answer = model.generate_content(prompt)
    return answer.text
  
  

def get_relevant_passage(query, db, n_results, max_distance_threshold=0.7):
    results = db.query(query_texts=[query], n_results=n_results)
    
    # Filter documents based on the distance threshold
    filtered_documents = []
    for doc, distance in zip(results['documents'], results['distances'][0]):
        if distance <= max_distance_threshold:  # Only consider documents below the threshold
            filtered_documents.append(doc)
    
    if not filtered_documents:  # No documents within the acceptable distance
        return None
    
    return filtered_documents[0]  # Return the top filtered document




def generate_answer(db, query):
    relevant_text = get_relevant_passage(query, db, n_results=3)
    if relevant_text is None:  # No relevant passage found
        prompt=make_rag_prompt(query, relevant_passage=query,val=2) 
        answer = generate_answer_api(prompt) 
        return answer
    
    prompt = make_rag_prompt(query, relevant_passage="".join(relevant_text),val=1)
    answer = generate_answer_api(prompt)
    return answer
  
  
current_dir = os.path.dirname(__file__)
file_path = os.path.join(current_dir, 'chroma_database_sang')   
db=load_chroma_collection(path= file_path, #replace with path of your persistent directory
                          name="reviews_collections") #replace with the collection name



app=Flask(__name__)
CORS(app)  


@app.route("/get-answer",methods=["POST"])
def func():
  data=request.get_json()
  question=data['question']
  answer = generate_answer(db, question)
  return answer

if __name__ == '__main__':
  app.run(debug=True)
